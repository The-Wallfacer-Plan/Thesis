\chapter{Preliminaries} \label{ch:preliminaries}

\begin{algorithm}[t]
 \small
\SetKwInOut{Input}{input}
	\SetKwInOut{Output}{output}
	\Input{Program \ProgO, Initial input seeds \Seeds}
	\Output{Final seeds \FinalSeeds, Vulnerable seeds \CrashSeeds}
	\Prog = instrument(\ProgO) \tcp*{instrumentation}
	$\CrashSeeds \leftarrow~\emptyset$, $\FinalSeeds \leftarrow~\Seeds$\; 
	\While {True} {
		$t$ = next\_seed(\FinalSeeds) \tcp*{seed selection}
		\mutChance = get\_mutation\_chance(t) \tcp*{power scheduling} \label{line:algo:energy}
		\For {$i\in~1\ldots \mutChance$} {
			t' = mutated\_input(t)  \tcp*{seed mutation}
			res = run(\Prog, t', \Ncal)\tcp*{calibration execution}
			\uIf {is\_crash(res)}{\label{line:algo:triage_start}
				$\CrashSeeds = \CrashSeeds\cup\{t'\}$ \tcp*{report vulnerable seeds}
			}\ElseIf {cov\_new\_trace(t', res)} {\label{line:algo:new_cov}
				$\FinalSeeds = \FinalSeeds\cup\{t'\}$ \tcp*{save "good" seeds} \label{line:algo:triage_end}
			}
		}
	}
	\caption{Greybox Fuzzing}\label{algo:gbf}
\end{algorithm}

In this chapter, we briefly describe the preliminaries, as well as terminologies used throughout the thesis.

\section{Greybox Fuzz Testing}\label{sec:intro-gbf}
Since its introduction in the early 1990s~\cite{fuzzing1990}, \emph{fuzz testing}, or \emph{fuzzing}, has remained highly popular due to its conceptual simplicity, its low barrier to deployment, and its vast amount of empirical evidence in discovering real-world software vulnerabilities~\cite{fuzz_survey}.

Greybox fuzzers (GBFs), which apply some instrumentations and utilize the collected dynamic statistics as feedback to guide the fuzzing procedure, have been proven to be effective in generating seeds and detecting vulnerabilities in modern programs~\cite{fuzz_survey}. Specially, AFL~\cite{afl}, libFuzzer~\cite{libfuzzer}, honggfuzz~\cite{honggfuzz} and the fuzzing infrastructure ClusterFuzz~\cite{clusterfuzz} have been able to detect more than 16,000 vulnerabilities or bugs in over 160 open source projects~\cite{afl,clusterfuzz}. Greybox fuzzing strikes a balance between mutation effectiveness and it execution speed. Compared to blackbox fuzzing, greybox fuzzing, to some extent, is aware of the structure of the target program under test via the instrumentation, therefore it has the capability to effectively guides the fuzzing procedure to much more valuable paths. Compared to white-box fuzzing techniques such as symbolic execution~\cite{dart,klee}, it is extremely lightweight and far more scalable to real-world projects.


Algorithm~\ref{algo:gbf} presents the core procedures of a typical greybox fuzzing algorithm. Basically, it involves an instrumentation step and a fuzzing loop. Given a target program \ProgO and input seeds \Seeds, a GBF first applies the instrumentation to track the coverage information in \ProgO. That is, the actual target program is \Prog. In spite of the difference, since the instrumentation typically does not significantly change the regular flow of a program's semantics, the crash on \Prog usually still indicates a weaknesses inside \ProgO. In practice, this difference is usually neglected.
The instrumentation can be done statically or dynamically. Static source instrumentation is usually applied during the source compilation procedure, with the help of compilation infrastructure such as LLVM~\cite{Lattner:2004:LCF:977395.977673}, GCC~\cite{gcc}. Dynamic binary instrumentation (DBI) is done with the help of DBI frameworks such as Valgrind~\cite{valgrind}, Intel PIN~\cite{pin}. Logically, instrumentation does not belong to fuzzing procedure, and its purpose is to collect feedback during fuzzing. Usually, the instrumentation does not involve deep static analyses.
The fuzzing loop does the actual mutations and testings against the program.
\begin{enumerate}[1.]
	\item Based on the seed priority, \emph{seed se15lection} selects next candidate seed $t$ from the queue which is formed by \Seeds.
	\item \emph{Seed mutation} procedure determines based on previous execution statistics on $t$ to determine how many mutation chances (\mutChance) will be provided for $t$.
	\item It enters the \emph{monitored execution} against the variants of $t$ with \mutChance iterations. 
	\begin{enumerate}[a)]
	\item Firstly, it applies \emph{seed mutation} on $t$ to generate a seed $t'$. 
	\item Secondly, it goes to the actual \emph{calibration execution} against $t'$; for statistics collection purpose, the fuzzer usually executes \Prog against $t'$ with continuously $\Ncal$ times. This is due to the fact that a single run on a specific seed may not be stable and the fuzzer needs to collect \emph{average statistics} for further scheduling.
	\item Finally, the fuzzer handles the generated seeds based on the execution results: the vulnerable seeds will be reported and those that are considered ``good'' according to the feedback will be appended to the seed queue for subsequent mutations.
	\end{enumerate}
\end{enumerate}
As the fuzzer's awareness of the program structure is based on the instrumentation feedback, a GBF typically does not \emph{know} the target program itself; therefore it usually has no idea when to stop the fuzzing procedure. In practice, however, this is not an issue since the fuzzing procedure is terminated manually or canceled within a time thredshold.

In the recent years, many approaches have been proposed to increase the fuzzing effectiveness in different aspects~\cite{Bohme:2016:CGF,LiCMLLT17,Bohme:2017:DGF,FairFuzz,CollAFL,Angora,nezha,fuzz_survey,issta19:deephunter,fse19:deepstellar}. For example, Angora~\cite{Angora} proposes to introduce fine-grained instrumentation and applies constraint solving to increase coverages; Coll-AFL~\cite{CollAFL} proposes a path sensitive approach to avoid collisions; Skyfire~\cite{junjie:2017sp:skyfire} attempts to improve the mutation operations on structure-sensitive programs. These have lead to further advances in the greybox fuzzing.

\section{Type Checking Based Verification}\label{sec:intro-sta}

\subsection{Type Checking for Information Flow Analysis}

Security type checking in securing information flow is based on the classification of program variables into different security labels. The simplest is to classify some variables as $L$, meaning low security (public), while other variables as $H$, meaning high security (private). The goal is to prevent private information variables from being leaked publicly, i.e., prevent information in $H$ variables from \emph{flowing} to $L$ variables.

As to \emph{confidentiality}, the common practice is to treat the set of the security labels as a  \emph{lattice} and the information flows only upwards in the lattice~\cite{Denning:1977hwa}. For example, since $L\leq H$, we would allow flows from $L$ to $L$, from $H$ to $H$, and from $L$ to $H$, but we would disallow flows from $H$ to $L$.

Below is an example taken from Denning~\cite{Denning:1976cl}. We assume \textsf{secret}$:H$ and \textsf{leak}$:L$, and the attacker can observe any variable at level $L$ but no variable at $H$.
From the confidentiality requirement, $\textsf{leak:=secret}$ is illegal while the assignment $\textsf{secret:=leak}$ works fine. This is due to the fact in the former case the secret information may be observed by the attacker when he/she sees the value of \textsf{leak}, which has the same value as \textsf{secret} after the assignment and is accessible by the attacker who has observation level not less than $L$. The leak is caused by an explicit data flow and is so-called \emph{explicit flow}. On the other hand, control flow can also leads to \emph{implicit flow} leaks. For example,
\begin{lstlisting}[language=c]
if ((secret mod 2) == 0) {
  leak := 0;
} else {
  leak := 1;	
}  
\end{lstlisting}

Despite that the \textsf{if-else} construct is not intended for data transfer, this segment is essentially equivalent to $\textsf{leak:=secret}$, which obviously violates the confidentiality. Therefore this is as dangerous as the direct assignment.

Some complex data structures may result in subtle information leaks. For example, if array \textsf{a} is initialized with all \textsf{0}s, then the program below is still leaking information due to the fact that after the execution, \textsf{leak} will be assigned to \textsf{i}, which is still the value of \textsf{secret}. There is also a leak from \textsf{secret} to \textsf{leak}.

\begin{lstlisting}[language=c]
a[secret] := 1;
for (int i := 0; i < a.length; i++) {
  if (a[i] == 1) leak := i;
}
\end{lstlisting}

\subsubsection{The Non-interference Property}
At a program level, the security properties are described as \emph{non-interference}, which was described by Goguen and Meseguer in 1982~\cite{Goguen:1982ta}. The simplest form tells that a deterministic program $c$ satisfies non-interference, if and only if, for any memories $\mu$ and $\nu$ that agree on $L$ variables, the memories produced by running $c$ on $\mu$ and on $\nu$ also agree on $L$ variables (provided that both terminate successfully). Basically, the program can be viewed as a state machine. If a low user is working on the machine, it will respond in exactly the same manner (on the low outputs) whether or not a high user is working with sensitive data. The low user will not be able to acquire any information about the activities (if any) of the high user by observing the values of low variables.

Typically, a security type system is introduced to prove the non-interference property. In addition to the regular types (such as integer, boolean, etc.), expressions and commands also contain security labels. And by applying the well-established typing derivation approach, it is fairly enough by reasoning over provided typing rules to verify the property, thus it provides a certificate to the underlying program.

%The non-interference property can also be applied to more complex systems when covert channels are considered. Implicit (control) flow can be seamlessly integrated into the typing rules by security typing on branching constructs. In fact, almost all security type systems handle implicit flows. Termination channels, which signal information through the termination or nontermination of a computation, can be handled by a revised termination-sensitive non-interference definition. Timing channels, probabilistic channels, resource exhaustion channels, and power channels, can also be encoded in a type system in order to preserve an adapted non-interference property.

\subsubsection{Typing Principles}

When applying type systems to guard information flows, a security label is typically associated with security type $\tau$ apart from the regular data type. The goal is to prove the soundness of the type system; that is, the problem survives the required security properties as long as it is well-typed in terms of the security types.

In Bell-Lapadula Model~\cite{bell1973}, it requires the subject at a given level must not write to any object at a lower security labels, and not read any object a higher security labels, which is characterized by the phrase ``no read up, no write down'', and it is safe to treat data that is low confidential to be high. In term of language based secure type systems, this is termed as \emph{Simple Security} and \emph{Confinement Security}. The former applies to expressions and later applies to commands. If an expression $e$ can be given type $\tau$ in the system, then Simple Security says, for secrecy, that only variables at level $\tau$ or lower in $e$ will have their contents accessed (read) when $e$ is evaluated (``no read up''). On the other hand, if a command $c$ can be given type $\tau$, then Confinement says, for secrecy, that no variable below level $\tau$ is updated (modified, writen) in $c$ (``no write down'').

The concrete security typing rules vary in the underlying type systems to guarantee these two properties. However, normally two subsumption rules are present in addition to the syntax-directed typing rules. That is, for expressions, it follows a co-variant view(\ruleTagText{Sub$_e$}); and for commands, it follows a contra-variant view(\ruleTagText{Sub$_c$}).

{\myeqsize\begin{equation*}
\inference
{e:\tau & \tau\leq\tau'}
{e:\tau'}
\ruleTagMath{Sub$_e$}
\qquad
\inference
{c:\tau & \tau'\leq\tau}
{c:\tau'}
\ruleTagMath{Sub$_c$}
\end{equation*}}
Intuitively, \ruleTagText{(Sub$_e$)} depicts the fact that it is always safe to read less confidential data as more confidential one; while \ruleTagText{(Sub$_c$)} discloses that if there is no variable below level $\tau$ updated in $c$, then there is surely no variable below $\tau'$ updated in $c$, as long as $\tau'\leq\tau$.


\subsection{IPC Mechanism in Android}

%\subsection{Android Security Model}
%The security model of Android system differs significantly from standard security models such as regular Bell-La Padula, mandatory access control (MAC), etc. In fact, Android applications (or apps for short) are treated as mutually distrusting principals: they are isolated from each other and do not have access to others' private (local) data. The mechanism is achieved by Android discretionary access control (DAC), which originates from Linux's access control mechanism. Next, we provide an overview of Android security model and its inter-process communication (IPC) facilities.
%
%\subsubsection{Thread Model}
%
%The Android Market contains a large number of third-party apps, and a user may install apps with different trust levels. Users install apps from unknown developers alongside trusted apps that handle private information such as financial data and personal photographs. For example, a user might install both a highly trusted payment app, as well as a free game app. In most of the scenarios, the user would not expect that the game app has access to the user's payment information.
%
%Under Android security model, all the apps are treated as potentially malicious. Each app runs in its own process with a low-privilege user ID, and apps can only access their own files by default. This isolation mechanism aims to protect apps with sensitive information from malware. Despite that, apps can inherently communicate via message passing (which is by convention called inter-process/app communication, IPC), which has been and is being utilized by various malware. In fact, the app might leak sensitive data, whenever the app sends information to the recipient without proper permission checking on the latter.

Android have become the mainstream of the smartphones. Android security has also long been the focus for security researchers, one of which belongs to the information leakage issue.
On Android, inter-process communication (IPC) is one of the major reasons that cause information leak, when the app sends sensitive data to the recipient but without proper permission checking on the latter.

%Intents are logical app building blocks delivered to app components. There are four categories of components in Android:

%\begin{description}
%	\item[Activity] components form the basis of the user interface. Typically, each activity corresponds to certain ``window'' in the underlying app.
%	\item[Service] components run as a daemon, and remain active even when the windows are switched. Services can expose interfaces for communication with other apps.
%	\item[BroadcastReceiver] components react asynchronously to messages from other apps.
%	\item[ContentProvider] components store app's data, usually in a database. Such data may sometimes be allowed to be shared across different apps.
%\end{description}

In particular, \emph{intents} are frequently used for message passing within or across apps. An intent is a message that declares a recipient, optionally with data. It can be thought of as a self-contained object that specifies a remote procedure to call and includes the associated arguments (remote procedure call, RPC). Intents are widely used for both inter-app communication and intra-app communication.

Intents are sent between three categories of Android components: Activities, Services, and Broadcast Receivers (excluding \emph{Content Provider}). They can be used for different purposes, such as starting Activities, starting, stopping, and binding Services, broadcasting information to BroadcastReceivers, etc. All of these communications can be used with explicit or implicit Intents.
Intents can be used for explicit or implicit communication. An explicit intent regulates that it should be delivered to a particular app with explicit app ID, whereas an implicit intent requests delivery to any app that satisfies certain properties. In other words, an explicit intent specifies the recipient by name, whereas an implicit intent's recipient(s) are eventually determined by the Android system based on the recipient's/recipients' support for certain operations. For example, consider an app that stores contact information. When a user clicks on one of his or her contacts' family address, the ``contacts app'' needs to ask another app to display a map of that location (in Android, it would be a \textsf{ACTION\_VIEW} action with the data URI of the scheme ``\textsf{geo:0,0?q=my+street+address}''). In this scenario, the contacts app could send an \emph{explicit intent} directly to Google Maps (in most cases, it is enough to call \textsf{intent.setPackage("com.google.android.apps.maps")} followed by a \textsf{startActivity(intent)}). Alternatively, it can send an \emph{implicit intent} that would be delivered to any app that also provides map service such as Yahoo! Maps (e.g., only \textsf{startActivity(intent)} is called). Using an explicit intent guarantees that it is delivered to the intended recipient, whereas implicit Intents allow for late runtime binding between different apps. {Typically, the resolution result is checked by calling of \textsf{intent.resolveActivity(getPackageManager())}, which is unknown until runtime.}